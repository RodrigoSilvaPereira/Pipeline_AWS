# ApresentaÃ§Ã£o Pessoal

<img src="https://avatars.githubusercontent.com/u/126106533?s=400&u=570115129a481f0705ced955273b889c44dc3722&v=4" width="75px" style="margin: 0 15px 0 0; border-radius: 99%" align="left">

<br> ğŸ—“ï¸ Rodrigo da Silva Pereira

<p>
  ğŸ‘‹ OlÃ¡, eu sou o Rodrigo! Um estudante de Desenvolvimento de Software Multiplataforma.

  - ğŸŒ± Tenho 19 anos e sou residente na cidade de Cajati, no interior de SÃ£o Paulo.
  
  - ğŸ“ Atualmente estou cursando o 5Â° semestre de Desenvolvimento de Software Multiplataforma na Fatec Registro.

  - ğŸ”­ Iniciei minha jornada profissional em marÃ§o de 2024, atravÃ©s do programa de bolsas Compass UOL, trabalhando na Ã¡rea de AWS Clouding.

  - ğŸ’¬ Possuo conhecimentos intermediÃ¡rios em inglÃªs e experiÃªncia prÃ¡tica em SQL, NoSQL, Java, Python, engenharia e anÃ¡lise de dados. Atualmente, sigo em busca de progredir em minha carreira profissional e aprofundar meus conhecimentos em Clouding e Data.

  - âš¡ AlÃ©m disso, sou apaixonado por leitura, absorvendo diversos tipos de conteÃºdos, e tambÃ©m gosto de passar meu tempo livre jogando.

  - ğŸŒŸ Sou uma pessoa dedicada, sempre em busca de aprendizado contÃ­nuo. Acredito que somos capazes de aprender tudo aquilo que nos interessa.
</p>

# Progresso e Conhecimentos

Durante meu estÃ¡gio na Compass UOL, tive a oportunidade de mergulhar em diversos aspectos da Ã¡rea de TI e enfrentar desafios empolgantes. Abaixo, compartilho alguns dos principais aprendizados e experiÃªncias que adquiri nessa etapa profissional.

## Sprint 1

### Aprendizados na Primeira Sprint

Durante a primeira sprint, tive a oportunidade de participar de um curso introdutÃ³rio sobre Linux - Ubuntu e Git - Github. Abaixo, compartilho um resumo dos principais tÃ³picos que aprendi:

#### Linux - Ubuntu
- ğŸ–¥ï¸ InstalaÃ§Ã£o e configuraÃ§Ã£o bÃ¡sica do sistema operacional Linux Ubuntu.
- ğŸ–¥ï¸ Comandos bÃ¡sicos do terminal, como navegar entre diretÃ³rios, criar e excluir arquivos e diretÃ³rios, entre outros.
- ğŸ“¦ Gerenciamento de pacotes usando o apt-get para instalar, atualizar e remover programas.
- ğŸ”’ NoÃ§Ãµes bÃ¡sicas de permissÃµes de arquivo e seguranÃ§a.

#### Git - Github
- ğŸŒ€ Conceitos fundamentais de controle de versÃ£o e a importÃ¢ncia do Git.
- ğŸŒ€ InicializaÃ§Ã£o de um repositÃ³rio Git local e o processo de commit.
- ğŸŒ Uso do GitHub para hospedar repositÃ³rios remotos e colaborar com outros desenvolvedores.
- ğŸŒ CriaÃ§Ã£o e gerenciamento de branches para trabalhar em paralelo em diferentes recursos.

Esses aprendizados foram essenciais para minha jornada como desenvolvedor e me prepararam para os desafios que enfrentarei em minha jornada de trabalho.

[Sprint 1](Sprint%201/README.md)
   
## Sprint 2

### Aprendizados na Segunda Sprint

Durante a segunda sprint, aproveitei a oportunidade para me aprofundar em um curso completo de SQL. Abaixo, compartilho um resumo dos principais tÃ³picos que aprendi:

#### SQL - Do bÃ¡sico ao AvanÃ§ado
- ğŸ“š Aprendizado dos conceitos fundamentais do SQL, incluindo consultas bÃ¡sicas, inserÃ§Ã£o, atualizaÃ§Ã£o e exclusÃ£o de dados.
- ğŸ“Š CompreensÃ£o aprofundada das clÃ¡usulas SELECT, WHERE, JOIN e GROUP BY para realizar consultas complexas em bancos de dados.
- ğŸ’¼ DomÃ­nio das tÃ©cnicas de modelagem de dados e normalizaÃ§Ã£o para projetar e otimizar a estrutura de bancos de dados.
- ğŸ” ExploraÃ§Ã£o de funÃ§Ãµes avanÃ§adas do SQL, como subconsultas, funÃ§Ãµes de agregaÃ§Ã£o, procedimentos armazenados e gatilhos.
- ğŸ“ˆ ImplementaÃ§Ã£o de estratÃ©gias de otimizaÃ§Ã£o de consultas para melhorar o desempenho e eficiÃªncia das operaÃ§Ãµes no banco de dados.
- ğŸ“ RealizaÃ§Ã£o de projetos prÃ¡ticos para aplicar os conhecimentos adquiridos em situaÃ§Ãµes do mundo real.

Esses conhecimentos adquiridos foram fundamentais para minha trajetÃ³ria como desenvolvedor e me capacitaram para enfrentar os desafios que surgirÃ£o ao longo da minha carreira!

[Sprint 2](Sprint%202/README.md)

## Sprint 3

### Aprendizado na Terceira Sprint

Python: Explorando e Aprendendo: Durante esta etapa do meu aprendizado, mergulhei fundo no mundo da programaÃ§Ã£o em Python. Abaixo, destaco algumas das atividades que realizei e o que aprendi:

#### ManipulaÃ§Ã£o de Dados com Pandas:
- ğŸ“Š Aprendi a carregar, limpar e manipular dados de diversas fontes usando a biblioteca Pandas.
- ğŸ“ˆ Explorei tÃ©cnicas avanÃ§adas de filtragem, seleÃ§Ã£o e agrupamento de dados para anÃ¡lise.
- ğŸ“‰ Utilizei Pandas para realizar cÃ¡lculos estatÃ­sticos e criar visualizaÃ§Ãµes informativas a partir dos dados.
#### VisualizaÃ§Ã£o de Dados com Matplotlib
- ğŸ“Š Criei grÃ¡ficos de linhas, barras, dispersÃ£o e pizza para representar visualmente os dados.
- ğŸ“ˆ Personalizei os grÃ¡ficos com cores, rÃ³tulos, legendas e outros elementos para tornÃ¡-los mais compreensÃ­veis e atraentes.
- ğŸ“‰ Explorei diferentes estilos e tipos de grÃ¡ficos para comunicar efetivamente insights a partir dos dados.
#### Projetos de AnÃ¡lise de Dados
- ğŸ“Š Trabalhei em projetos prÃ¡ticos para analisar conjuntos de dados do mundo real e extrair insights valiosos.
- ğŸ“ˆ Utilizei Python para responder a perguntas especÃ­ficas e resolver problemas analÃ­ticos usando os dados disponÃ­veis.
- ğŸ“‰ Apliquei tÃ©cnicas de visualizaÃ§Ã£o e anÃ¡lise de dados para comunicar resultados de forma clara e eficaz.

Essas experiÃªncias me proporcionaram uma compreensÃ£o mais profunda do Python como uma ferramenta poderosa para anÃ¡lise de dados e visualizaÃ§Ã£o. Estou entusiasmado para continuar explorando e expandindo meu conhecimento neste domÃ­nio emocionante da programaÃ§Ã£o!

[Sprint 3](Sprint%203/README.md)

## Sprint 4

### Aprendizado na Quarta Sprint

Docker: Explorando e Aprendendo: Durante este curso, mergulhei fundo no universo do Docker, uma ferramenta essencial para o desenvolvimento e implantaÃ§Ã£o de aplicativos em contÃªineres. Abaixo, destaco algumas das atividades que realizei e o que aprendi:

### ConstruÃ§Ã£o e Gerenciamento de ContÃªineres com Docker:
- ğŸ³ Aprendi a criar, gerenciar e distribuir contÃªineres usando Docker, uma ferramenta fundamental para a implantaÃ§Ã£o de aplicativos modernos.
- ğŸ“¦ Explorei tÃ©cnicas avanÃ§adas de configuraÃ§Ã£o e otimizaÃ§Ã£o de contÃªineres para diferentes ambientes de implantaÃ§Ã£o.
- ğŸš€ Utilizei Docker para criar imagens eficientes e escalÃ¡veis para aplicativos em contÃªineres.
### OrquestraÃ§Ã£o de ContÃªineres com Docker Compose e Kubernetes:
- ğŸ³ Configurei e gerenciei aplicativos multi-contÃªineres usando Docker Compose, simplificando o desenvolvimento e implantaÃ§Ã£o de aplicaÃ§Ãµes complexas.
- âš™ï¸ Explorei o Kubernetes como uma plataforma de orquestraÃ§Ã£o de contÃªineres para dimensionamento automÃ¡tico, tolerÃ¢ncia a falhas e implantaÃ§Ã£o simplificada de aplicativos em contÃªineres.
- ğŸŒ Aprendi a usar recursos avanÃ§ados do Kubernetes para implantar, atualizar e monitorar aplicativos em escala.
### ImplantaÃ§Ã£o de AplicaÃ§Ãµes em Ambientes de ProduÃ§Ã£o:
- ğŸ³ Trabalhei em projetos prÃ¡ticos para implantar e gerenciar aplicativos Docker em ambientes de produÃ§Ã£o.
- âš™ï¸ Utilizei tÃ©cnicas de monitoramento e escalabilidade para garantir o desempenho e a disponibilidade dos aplicativos em contÃªineres.
- ğŸŒ Apliquei prÃ¡ticas recomendadas de seguranÃ§a e manutenÃ§Ã£o para garantir a integridade e a confiabilidade das implantaÃ§Ãµes em contÃªineres.

Essas experiÃªncias me proporcionaram uma compreensÃ£o mais profunda do Docker como uma ferramenta poderosa para o desenvolvimento, implantaÃ§Ã£o e gerenciamento de aplicativos em contÃªineres.

[Sprint 4](Sprint%204/README.md)

## Sprint 5

### Aprendizado na Quinta Sprint

Durante a quinta sprint, concentrei-me em explorar e aprofundar meus conhecimentos em AWS S3 com Boto3. Abaixo, destaco algumas das atividades que realizei e o que aprendi:

### ConstruÃ§Ã£o e Gerenciamento de ServiÃ§os S3:
- ğŸ› ï¸ Aprendi a interagir com o Amazon Simple Storage Service (S3) usando a biblioteca Boto3, uma ferramenta essencial para manipulaÃ§Ã£o de objetos no armazenamento em nuvem da AWS.
- ğŸ“‚ Explorei tÃ©cnicas para listar, carregar, baixar e excluir objetos em buckets do S3 utilizando operaÃ§Ãµes programÃ¡ticas.
- ğŸ”„ Utilizei as capacidades de controle de acesso do S3 para gerenciar permissÃµes de acesso a buckets e objetos, garantindo a seguranÃ§a dos dados armazenados.
### AutomatizaÃ§Ã£o de Tarefas com AWS S3 e Boto3:
- âš™ï¸ Desenvolvi scripts Python para automatizar tarefas rotineiras de gerenciamento de dados no S3, como sincronizaÃ§Ã£o de arquivos, cÃ³pias de seguranÃ§a e monitoramento de eventos.
- ğŸ¤– Explorei a integraÃ§Ã£o do AWS S3 com outros serviÃ§os da AWS, como Lambda, SNS e CloudWatch, para construir pipelines de dados automatizados e escalÃ¡veis.

Essas experiÃªncias me proporcionaram uma compreensÃ£o mais profunda do AWS S3 e do Boto3 como ferramentas poderosas para armazenamento e gerenciamento de dados na nuvem da AWS. Estou entusiasmado para continuar explorando e expandindo meu conhecimento neste domÃ­nio emocionante da computaÃ§Ã£o em nuvem e DevOps!

[Sprint 5](Sprint%205/README.md)

## Sprint 6

### Aprendizado na Sexta Sprint

Durante a sexta sprint, concentrei-me em consolidar e expandir meus conhecimentos em AWS S3 com Boto3, alÃ©m de explorar novos desafios e conceitos. Abaixo, destaco algumas das atividades que realizei e o que aprendi:

### ManipulaÃ§Ã£o AvanÃ§ada de Dados no AWS S3:
- ğŸ› ï¸ Aprofundei minha compreensÃ£o sobre a manipulaÃ§Ã£o de dados no Amazon Simple Storage Service (S3) usando a biblioteca Boto3, explorando tÃ©cnicas avanÃ§adas para operaÃ§Ãµes de leitura, escrita e manipulaÃ§Ã£o de objetos em buckets do S3.
- ğŸ“‚ Trabalhei com operaÃ§Ãµes avanÃ§adas de gerenciamento de objetos, como controle de versÃµes, criptografia de dados, e utilizaÃ§Ã£o de metadados para categorizaÃ§Ã£o e organizaÃ§Ã£o eficiente de dados armazenados.
- ğŸ”„ Aprendi sobre a implementaÃ§Ã£o de pipelines de dados mais complexos e robustos, incluindo a integraÃ§Ã£o do AWS S3 com serviÃ§os de processamento de dados, como AWS Glue e Amazon EMR.

Essas experiÃªncias me proporcionaram uma base sÃ³lida e abrangente em AWS S3 e Boto3, capacitando-me a enfrentar desafios cada vez mais complexos na Ã¡rea de armazenamento e gerenciamento de dados na nuvem!

[Sprint 6](Sprint%206/README.md)

## Sprint 7

### Aprendizado na SÃ©tima Sprint

Durante a sÃ©tima sprint, concentrei-me na criaÃ§Ã£o de um desafio envolvendo AWS Lambda para processamento de dados no Amazon S3. Abaixo, destaco as principais atividades realizadas e o aprendizado adquirido:

### IntegraÃ§Ã£o de AWS Lambda com Amazon S3
- ğŸ› ï¸ **Desenvolvimento**: Criei um script Python para integraÃ§Ã£o entre AWS Lambda e Amazon S3.
- ğŸ” **Funcionalidades**: A funÃ§Ã£o Lambda lÃª dados de um arquivo CSV no S3, processa registros de filmes baseado em critÃ©rios especÃ­ficos e salva os dados filtrados em JSON de volta no S3.
- ğŸ–¥ï¸ **Tecnologias Utilizadas**: Boto3 para interaÃ§Ã£o com o S3, AWS Lambda para transformaÃ§Ã£o automaÃ§Ã£o e integraÃ§Ã£o.

Essas experiÃªncias me proporcionaram uma base sÃ³lida e abrangente em S3 e Lambda, capacitando-me a enfrentar desafios cada vez mais complexos na Ã¡rea de armazenamento e gerenciamento de dados na nuvem. Estou animado para continuar expandindo meu conhecimento e explorando novas possibilidades neste domÃ­nio fascinante da computaÃ§Ã£o em nuvem e DevOps!

[Sprint 7](Sprint%207/README.md)

## Sprint 8

### Aprendizado na Oitava Sprint

Durante a oitava sprint, concentrei-me na criaÃ§Ã£o de um desafio envolvendo AWS Glue e Spark para processamento de dados no Amazon S3. Abaixo, destaco as principais atividades realizadas e o aprendizado adquirido:

### IntegraÃ§Ã£o de AWS Glue com Amazon S3
- ğŸ› ï¸ **Desenvolvimento**: Criei scripts Python para integraÃ§Ã£o entre AWS Glue e Amazon S3.
- ğŸ” **Funcionalidades**: Os scripts leem dados de arquivos CSV e JSON no S3, processam os registros com base em critÃ©rios especÃ­ficos (como gÃªnero 'Sci-Fi' e 'Fantasy' para CSV) e salvam os dados transformados em formato Parquet de volta no S3.
- ğŸ–¥ï¸ **Tecnologias Utilizadas**: PySpark para processamento de dados, AWS Glue para automaÃ§Ã£o e integraÃ§Ã£o, e Amazon S3 para armazenamento.

Essas experiÃªncias me proporcionaram uma base sÃ³lida e abrangente em AWS Glue e Spark, capacitando-me a enfrentar desafios cada vez mais complexos na Ã¡rea de processamento e gerenciamento de dados na nuvem.

[Sprint 8](Sprint%208/README.md)

## Sprint 9

### Aprendizado na Nona Sprint

Durante a nota sprint, concentrei-me no refinamento dos dados que seriam utilizados na visualizaÃ§Ã£o:

### IntegraÃ§Ã£o de AWS Glue com Amazon S3
- ğŸ› ï¸ **Refinamento**: Refinamos dados da camada "trusted" para garantir que os dados utilizados na visualizaÃ§Ã£o sejam precisos e confiÃ¡veis.
- ğŸ” **Leitura de Parquet**: Lemos os arquivos Parquet gerados pelo AWS Glue e processamos os dados para garantir que eles estejam na forma correta para a visualizaÃ§Ã£o.
- ğŸ–¥ï¸ **Tecnologias Utilizadas**: PySpark para processamento de dados, AWS Glue para automaÃ§Ã£o e integraÃ§Ã£o, e Amazon S3 para armazenamento.

Este processo envolveu a leitura dos arquivos Parquet, a junÃ§Ã£o dos dados das fontes TMDB e API, a exploraÃ§Ã£o da coluna "genero_filme" para desaninhar os gÃªneros de cada filme, seleÃ§Ã£o e renomeaÃ§Ã£o de colunas para garantir consistÃªncia nos dados. O resultado foi armazenado de volta no S3, estruturado e pronto para ser utilizado em anÃ¡lises subsequentes utilizando serviÃ§os como Athena e QuickSight.

[Sprint 9](Sprint%209/README.md)

## Sprint 10

### Aprendizado na DÃ©cima

Durante a dÃ©cima sprint, concentrei-me na criaÃ§Ã£o e otimizaÃ§Ã£o de dashboards no AWS QuickSight, utilizando dados refinados e armazenados no Amazon S3. Abaixo, destaco as principais atividades realizadas e o aprendizado adquirido:

### CriaÃ§Ã£o de Dashboards com AWS QuickSight
- ğŸ“Š **Desenvolvimento**: Utilizei AWS QuickSight para criar dashboards detalhados e visualmente atraentes, baseados nos dados tratados nas sprints anteriores. O foco principal foi na anÃ¡lise de subgÃªneros do gÃªnero "Speculative".
- ğŸ“ˆ **Funcionalidades**: Realizei anÃ¡lises aprofundadas sobre os subgÃªneros dos filmes, identificando a frequÃªncia e outras mÃ©tricas importantes para fornecer insights valiosos.
- ğŸ–¥ï¸ **Tecnologias Utilizadas**: Amazon S3 para armazenamento escalÃ¡vel de dados, Amazon Athena para consultas SQL na nuvem e AWS QuickSight para visualizaÃ§Ãµes interativas e detalhadas.

Essas experiÃªncias me proporcionaram um entendimento mais profundo de visualizaÃ§Ã£o de dados, anÃ¡lise de dados em nuvem e criaÃ§Ã£o de dashboards interativos com AWS QuickSight. Estou entusiasmado para aplicar este conhecimento em desafios futuros e continuar explorando novas capacidades na Ã¡rea de visualizaÃ§Ã£o e anÃ¡lise de dados.

[Sprint 10](Sprint%20Final%2010/README.md)
