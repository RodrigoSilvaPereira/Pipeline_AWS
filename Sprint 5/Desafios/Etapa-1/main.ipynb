{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração e Script para Listar Buckets no Amazon S3\n",
    "\n",
    "Este guia passo a passo mostra como configurar o AWS CLI usando AWS SSO (Single Sign-On) e como executar um script Python para listar os buckets no Amazon S3.\n",
    "\n",
    "## Configuração do AWS CLI com AWS SSO\n",
    "\n",
    "Para usar AWS SSO, você precisa configurar o AWS CLI para autenticação SSO e criar um perfil. Siga os passos abaixo:\n",
    "\n",
    "### 1. Configurar AWS CLI com AWS SSO\n",
    "\n",
    "1. **Configurar AWS SSO**:\n",
    "   ```sh\n",
    "   aws configure sso\n",
    "\n",
    "#### Seguir as instruções:\n",
    "- Insira a URL do portal do SSO.\n",
    "- Insira a região do SSO.\n",
    "- Siga o link gerado para se autenticar.\n",
    "- Selecione a conta e permissões desejadas.\n",
    "- Dê um nome ao perfil (ex.: default).\n",
    "\n",
    "**Uma vez criado o usuário, podemos realizar o login sempre que necessário, sem precisar configurar novamente, através do comando:**\n",
    "   ```sh\n",
    "   aws sso login --profile default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar Buckets no Amazon S3 usando boto3\n",
    "\n",
    "Este script Python utiliza a biblioteca boto3 para listar os buckets no Amazon S3. Ele faz uso de perfis configurados na AWS CLI para autenticação.\n",
    "\n",
    "### Pré-requisitos\n",
    "\n",
    "1. **Instalar boto3**\n",
    "   Certifique-se de que boto3 está instalado. Você pode instalá-lo usando pip:\n",
    "   ```sh\n",
    "   pip install boto3\n",
    "\n",
    "### Funcionamento\n",
    "- Importações: Importa boto3 para interagir com os serviços da AWS e as exceções necessárias do botocore.\n",
    "\n",
    "- Função list_s3_buckets:\n",
    "- Sessão e Cliente S3: Inicializa uma sessão usando o perfil AWS configurado e cria um cliente S3.\n",
    "- Listagem de Buckets: Obtém a lista de buckets chamando s3.list_buckets().\n",
    "- Verificação e Impressão: Verifica se a lista de buckets está vazia e imprime os nomes dos buckets encontrados.\n",
    "- Tratamento de Exceções: Lida com exceções relacionadas a credenciais ausentes ou incompletas e outros erros gerais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets encontrados:\n",
      " - desafiosprintrodrigo\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "\n",
    "\n",
    "def list_s3_buckets():\n",
    "    try:\n",
    "        # Inicializa o cliente S3 usando o perfil configurado\n",
    "        session = boto3.Session(profile_name=\"default\")\n",
    "        s3 = session.client(\"s3\")\n",
    "\n",
    "        # Lista os buckets\n",
    "        response = s3.list_buckets()\n",
    "\n",
    "        buckets = response.get(\"Buckets\", [])\n",
    "\n",
    "        if not buckets:\n",
    "            print(\"Nenhum bucket encontrado.\")\n",
    "        else:\n",
    "            print(\"Buckets encontrados:\")\n",
    "            for bucket in buckets:\n",
    "                print(f\" - {bucket['Name']}\")\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credenciais não encontradas.\")\n",
    "    except PartialCredentialsError:\n",
    "        print(\"Credenciais incompletas.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    list_s3_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de Bucket no Amazon S3\n",
    "\n",
    "Este guia demonstra como criar um bucket no Amazon S3 usando Python e boto3, garantindo que o nome do bucket seja único ao adicionar um identificador UUID.\n",
    "\n",
    "### Pré-requisitos\n",
    "\n",
    "1. **AWS CLI Configurado**: Certifique-se de que você configurou o AWS CLI e autenticou com sucesso usando AWS SSO ou chaves de acesso.\n",
    "2. **Biblioteca boto3**: Instale boto3 se ainda não tiver instalado. Você pode fazer isso usando pip:\n",
    "   ```sh\n",
    "   pip install boto3\n",
    "\n",
    "#### Explicação do Código\n",
    "\n",
    "##### Importações:\n",
    "\n",
    "- boto3 para interagir com os serviços da AWS.\n",
    "\n",
    "**Função create_s3_bucket:**\n",
    "\n",
    "- Inicialização do Cliente S3: Cria uma sessão boto3 usando o perfil padrão configurado.\n",
    "\n",
    "- Criação do Bucket: Verifica a região e cria o bucket. Se a região for us-east-1, não configura LocationConstraint.\n",
    "\n",
    "- Tratamento de Exceções: Lida com exceções específicas e genéricas, incluindo a verificação de buckets já existentes.\n",
    "\n",
    "##### Uso da Função:\n",
    "\n",
    "Chama a função create_s3_bucket com o nome do bucket e a região especificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'desafiosprintrodrigo' criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n",
    "\n",
    "\n",
    "def create_s3_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        # Inicializa a sessão e o cliente S3 usando o perfil configurado\n",
    "        session = boto3.Session(profile_name=\"default\")\n",
    "        s3_client = session.client(\"s3\", region_name=region)\n",
    "\n",
    "        # Cria o bucket com a região especificada\n",
    "        if region is None or region == \"us-east-1\":\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            location = {\"LocationConstraint\": region}\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name, CreateBucketConfiguration=location\n",
    "            )\n",
    "\n",
    "        print(f\"Bucket '{bucket_name}' criado com sucesso.\")\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credenciais não encontradas.\")\n",
    "    except PartialCredentialsError:\n",
    "        print(\"Credenciais incompletas.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"Ocorreu um erro ao tentar criar o bucket: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "bucket_name = \"desafiosprintrodrigo\"\n",
    "region = \"us-east-1\"\n",
    "create_s3_bucket(bucket_name, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload do Arquivo para o Bucket\n",
    "\n",
    "### Importações:\n",
    "\n",
    "- Importa **boto3** para interagir com os serviços da AWS.\n",
    "- Importa exceções relevantes do **botocore**.\n",
    "\n",
    "### Função upload_file_to_s3:\n",
    "\n",
    "- Inicialização do Cliente S3: Cria uma sessão boto3 usando o perfil padrão configurado e inicializa o cliente S3.\n",
    "- Nome do Objeto: Se object_name não for fornecido, usa o file_path como nome do objeto no S3.\n",
    "- Upload do Arquivo: Usa s3_client.upload_file para enviar o arquivo para o bucket S3.\n",
    "- Tratamento de Exceções: Lida com exceções específicas e genéricas.\n",
    "\n",
    "### Uso da Função:\n",
    "\n",
    "- Define bucket_name, file_path, e object_name (opcional).\n",
    "- Chama a função upload_file_to_s3 para fazer o upload do arquivo para o bucket S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'date/infracos_transito_07_2023.csv' enviado para o bucket 'desafiosprintrodrigo' como 'infracos_transito_07_2023.csv'.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n",
    "\n",
    "\n",
    "def upload_file_to_s3(bucket_name, file_path, object_name=None):\n",
    "    try:\n",
    "        # Inicializa a sessão e o cliente S3 usando o perfil configurado\n",
    "        session = boto3.Session(profile_name=\"default\")\n",
    "        s3_client = session.client(\"s3\")\n",
    "\n",
    "        # Se o nome do objeto não for especificado, usa o nome do arquivo\n",
    "        if object_name is None:\n",
    "            object_name = file_path\n",
    "\n",
    "        # Faz o upload do arquivo\n",
    "        s3_client.upload_file(file_path, bucket_name, object_name)\n",
    "\n",
    "        print(\n",
    "            f\"Arquivo '{file_path}' enviado para o bucket '{bucket_name}' como '{object_name}'.\"\n",
    "        )\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credenciais não encontradas.\")\n",
    "    except PartialCredentialsError:\n",
    "        print(\"Credenciais incompletas.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"Ocorreu um erro ao tentar enviar o arquivo: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "\n",
    "bucket_name = \"desafiosprintrodrigo\"\n",
    "file_path = \"date/infracos_transito_07_2023.csv\"\n",
    "object_name = \"infracos_transito_07_2023.csv\"\n",
    "\n",
    "upload_file_to_s3(bucket_name, file_path, object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta SQL com Pandasql\n",
    "\n",
    "### Descrição:\n",
    "\n",
    "Este código Python realiza uma consulta SQL em um DataFrame do Pandas utilizando a biblioteca pandasql. Ele faz o upload de um arquivo CSV de um bucket S3 da AWS, lê esse arquivo em um DataFrame do Pandas e executa uma consulta SQL contida em um arquivo externo.\n",
    "\n",
    "#### Função openQuery:\n",
    "\n",
    "- Descrição: Esta função é responsável por abrir um arquivo contendo uma consulta SQL e retornar o conteúdo como uma string.\n",
    "- Parâmetros de entrada: Recebe o nome do arquivo contendo a consulta SQL.\n",
    "- Saída: Retorna a consulta SQL como uma string.\n",
    "\n",
    "#### Uso da Função:\n",
    "- Bucket S3: Define o nome do bucket S3 de onde será feito o download do arquivo CSV.\n",
    "- Arquivo CSV: Define o nome do arquivo CSV no bucket S3 a ser baixado.\n",
    "- Consulta SQL: Define o nome do arquivo contendo a consulta SQL a ser executada.\n",
    "- Leitura do Arquivo CSV: Utiliza a biblioteca boto3 para fazer o download do arquivo CSV do bucket S3 e a função read_csv do Pandas para ler o arquivo em um DataFrame do Pandas.\n",
    "- Execução da Consulta SQL: Utiliza o pandasql para executar a consulta SQL no DataFrame do Pandas.\n",
    "- Exportação do Resultado: Exporta o resultado da consulta para um arquivo CSV localmente.\n",
    "\n",
    "#### Dependências:\n",
    "\n",
    "- boto3: Utilizada para interagir com os serviços da AWS, neste caso, para baixar o arquivo CSV do S3.\n",
    "- pandas: Utilizada para manipulação e análise de dados, incluindo a leitura do arquivo CSV em um DataFrame.\n",
    "- pandasql: Utilizada para executar consultas SQL em DataFrames do Pandas.\n",
    "- botocore.exceptions: Importa exceções relevantes do botocore, que podem ser tratadas durante a interação com o cliente S3.\n",
    "\n",
    "##### Exceções Tratadas:\n",
    "Erro ao Ler Arquivo CSV: Trata exceções que podem ocorrer ao tentar ler o arquivo CSV do S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantidade_registros               tipo_veiculo  infracoes_velocidade  \\\n",
      "0                 25379  AUTOMOVEL                                 20046   \n",
      "1                 18234                  AUTOMOVEL                 16549   \n",
      "\n",
      "   quantidade_condutores latitude_media  ano_cometimento  \\\n",
      "0                  25379           None             2023   \n",
      "1                  18234           None             2023   \n",
      "\n",
      "                                     descricao_curta  data_atual  \n",
      "0  Transitar em velocidade superior à máxima perm...  2024-05-20  \n",
      "1  Transitar em velocidade superior à máxima perm...  2024-05-20  \n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "session = boto3.Session(profile_name='default')\n",
    "sess = boto3.Session(region_name='us-east-1')\n",
    "s3Client = session.client('s3')\n",
    "\n",
    "bucket_name = 'desafiosprintrodrigo'\n",
    "\n",
    "def openQuery(nomeQuery):\n",
    "    with open(nomeQuery, 'r') as qy:\n",
    "        query = qy.read() \n",
    "        return query\n",
    "\n",
    "\n",
    "try:\n",
    "    response = s3Client.get_object(Bucket=bucket_name, Key='infracos_transito_07_2023.csv')\n",
    "    df = pd.read_csv(response['Body'], delimiter=';')\n",
    "    consulta = openQuery('consulta.sql')\n",
    "    print(ps.sqldf(consulta, locals()))\n",
    "    \n",
    "    dataframe_como_csv = pd.DataFrame(ps.sqldf(consulta, locals()))\n",
    "    dataframe_como_csv.to_csv(r'consulta.csv', index=False)\n",
    "   \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo CSV do S3: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
